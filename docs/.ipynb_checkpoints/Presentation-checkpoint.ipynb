{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efca54f5-b38c-4ab2-b7d9-2414d2c1c801",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"res/img/logo.png\" width=\"512\" height=\"512\" align=\"center\"/></center>\n",
    "<center><h1>Documentinator</h1><h3>Speed up your docs categorization.</h3></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67912436",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h1>Documentinator: Informazioni sul progetto</h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0beae847",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<p style=\"font-size:24px;\">Questo progetto si occupa di analizzare e categorizzare dei documenti. L'idea è quella di automatizzare la deduzione del contenuto e l'attendibilità di un documento.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7faafac0",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<p style=\"font-size:24px;\">Con la digitalizzazione della maggior parte delle compagnie, dei servizi forniti da esse e anche con la semplice digitalizzazione della vita quotidiana, abbiamo quasi del tutto abbandonato il cartaceo. La digitalizzazione ci fa risparmiare molte risorse e molto tempo, e questo progetto punta proprio a diminuire ancora l'analisi dei documenti digitalizzati.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83739436",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h1>Cosa fa?</h1></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b59bb7",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<p style=\"font-size:24x;\">Documentinator, attende l'inserimento in una cartella di nuovi documenti. Di questi viene estratto il contenuto e poi viene analizzato usando l'API di OpenAI. Le informazioni che vogliamo ottenere sono:\n",
    "    <ul>\n",
    "        <li><b>Categoria</b>: vogliamo sapere in che categoria appartiene il documento digitale.</li>\n",
    "        <li><b>Riassunto</b>: vogliamo avere un breve riassunto di tutto il documento.</li>\n",
    "        <li><b>Attendibilità</b>: vogliamo avere un indice di attendibilità delle infomrazioni contenute nel documento.</li>\n",
    "    </ul> \n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c613cf",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><h1>Come lo fa?</h1></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5729caf",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "<p style=\"font-size:24x;\">Diamo un occhiata alla pipeline del progetto per capire come avviene il tutto.\n",
    "</p>\n",
    "<center><img src=\"res/img/pipeline.png\"></img></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092caf4d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><h1>Python service</h1><center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bceebf7",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<p style=\"font-size:24x;\">\n",
    "Questa prima parte è semplicemente un servizio che controlla una directory in attesa di un nuovo documento. \n",
    "    <br>Quando ne rileva uno, tramite un Observer sulla directory, lo analizza formando un json che avrà il seguente formato:\n",
    "    <pre><code><br>file_data = {\n",
    "        \"uuid\": \"uuid generato\",\n",
    "        \"file_name\": \"nome del file\",\n",
    "        \"file_size\": \"dimensioni del file\",\n",
    "        \"file_extension\": \"estensione del file\",\n",
    "        \"content\": \"contenuto estratto dal file\",\n",
    "        \"last_edit\": \"ultima modifica del file\"\n",
    "    }</code></pre>\n",
    "<br> Momentaneamente questo servizio è in grado di esaminare file di tipo: .png', '.jpg', '.jpeg', '.tiff', '.bmp', '.gif', '.pdf', '.txt'.\n",
    " Le immagini, o i pdf che non contengono testo, vengono esaminati con un OCR\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671823d3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h1>Fluentd</h1></center>\n",
    "<p style=\"font-size:23x; margin-top:0\">\n",
    "Fluentd viene usato per fare la data ingestion cosi da poter proseguire nel resto della pipeline.\n",
    "    <br>La scelta di usare Fluentd è stata determinata dalla sua semplicità di configurazione e per l'ampio repertorio di estensioni, che in caso di necessità future possono essere facilmente implementate.<br>Per lo stato di test la scelta della tecnologia influisce poco quindi:\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9b4553",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center style='margin-top:0;'><img src='res/img/why_pick_fluentd.png' width='512'></img></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0201da82",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h1>Kafka</h1></center>\n",
    "<p style=\"font-size:24x;\">\n",
    "    <b>Kafka</b> viene usato nella nostra pipeline per fare da broker tra Fluentd e i consumer collegati alla nostra pipeline.\n",
    "    <br>Uno di questi consumer sfrutta Kafka stesso, questo consumer è stato usato per Log di debug. Può essere disabilitato semplicemente rimuovendo la riga relativa ad esso nel docker-compose.\n",
    "   \n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9555654",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h1>Spark</h1></center>\n",
    "<p style=\"font-size:24x;\">\n",
    "    <b>Spark</b> grazie alle sue librerie è in grado di interfacciarsi a Kafka in maniera quasi del tutto naturale.\n",
    "    <br>Con molta semplicità si è in grado di ottenere i dati provenienti dal Topic di Kafka e quindi poterli poi arricchire.\n",
    "    <br>&Egrave; qui che entra in gioco l'API di openAI che, analizzando il contenuto, ci fornisce le informazioni per categorizzare il nostro documento.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3b69ef",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h1>Prompt per openAI</h1></center>\n",
    "<p style=\"font-size:24x;\">\n",
    "Una cosa molto importanta è proprio quella di definire il nostro prompt per l'IA.\n",
    "    <br>Per ricevere un formato di risposta standardizzato dall'IA è stato necessario fare un prompt adeguato.\n",
    "    <p style='quotes: \"«\" \"»\" \"‹\" \"›\";'>\n",
    "You are an expert data analyst helping us to understand the content of a document based on the title and the content\n",
    "    <br>You'll receive an input with the following format: filename: &lt;filename&gt;  content: &lt;content&gt;\n",
    "    <br>Your task is to tell us in what category the document could go: personal, business, game, payment, recipe, receipt or if it's not possible to understand use the category 'other'.\n",
    "    <br>Give a small summary of what the document contains in less than 25 words. \n",
    "    <br>And on a scale from 1 to 10, rate the reliability of the document information.\n",
    "    <br>Your answer must be in this format only without descriptions or other text added: category: &lt;category&gt;, summary: &lt;summary&gt;, reliability: &lt;reliability&gt;\n",
    "</p>\n",
    "<br>Proviamo quindi un'esempio di due documenti. Uno dettagliato e corretto e l'altro palesemente non attendibile.\n",
    "</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60169e0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h1>Esempio con file attendibile:</h1></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f5c2259c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category: recipe\n",
      "summary: The document contains a recipe for flavorful baked pasta, including preparation, cooking, serving suggestions, and storage tips\n",
      "reliability: 9\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "import openai\n",
    "openai.api_key = os.getenv('API_KEY')\n",
    "file_path = 'res/pasta_al_forno.txt'\n",
    "file_name = os.path.basename(file_path)\n",
    "with open('res/prompt.txt', 'r') as file:\n",
    "    prompt = file.read()\n",
    "with open(file_path, 'r') as file:\n",
    "    content = file.read()\n",
    "file_data = 'filename: '+file_name+', content: '+content;\n",
    "response = openai.chat.completions.create(model=\"gpt-4\",messages=[{\"role\": \"user\", \"content\": prompt + \"\\n\" + file_data},],)\n",
    "reply = response.choices[0].message.content\n",
    "print(reply.replace('; ', '\\n'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f8bae1",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><h1>Esempio con file non-attendibile:</h1></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "028c9217",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category: game\n",
      "summary: A playful, nonsensical guide to cooking chicken involving travel, a river, and impossible oven temperature\n",
      "reliability: 1\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "import openai\n",
    "openai.api_key = os.getenv('API_KEY')\n",
    "file_path = 'res/pollo_fritto.txt'\n",
    "file_name = os.path.basename(file_path)\n",
    "with open('res/prompt.txt', 'r') as file:\n",
    "    prompt = file.read()\n",
    "with open(file_path, 'r') as file:\n",
    "    content = file.read()\n",
    "file_data = 'filename: '+file_name+', content: '+content;\n",
    "response = openai.chat.completions.create(model=\"gpt-4\",messages=[{\"role\": \"user\", \"content\": prompt + \"\\n\" + file_data},],)\n",
    "reply = response.choices[0].message.content\n",
    "print(reply.replace('; ', '\\n'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64716030",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p style=\"font-size:24x;\">\n",
    "    back on track...\n",
    "</p>\n",
    "<center><h1>Elasticsearch e Kibana</h1></center>\n",
    "\n",
    "<p style=\"font-size:24x;\">\n",
    "Questi due ultimi strumenti vanno molto a braccetto, l'integrazione è praticamente immediata.\n",
    "    <br><b>Elasticsearch</b> ci offre capacità di ricerca e indicizzazione in grado di gestire grandi volumi di dati in tempo reale. La sua architettura fornisce scalabilità e prestazioni elevate.\n",
    "    <br><b>Kibana</b> fornisce invece un'interfaccia utente intuitiva per visualizzare e analizzare dati indicizzati in Elasticsearch. Offre potenti dashboard e strumenti di visualizzazione come grafici e mappe, facilitando l'interpretazione dei dati.\n",
    "</p>\n",
    "<center><img src=\"res/img/elasticseachxkibana.png\"></img></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3152632a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h1>Esempio Visualizzazione:</h1></center>\n",
    "<p style=\"font-size:24x;\">\n",
    "    //todo\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc94fb5",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><h1>Prospetti futuri</h1></center>\n",
    "<p style=\"font-size:24x;\">\n",
    "    Il progetto è in una sua fase iniziale che ci permette di vedere il suo funzionamento, di seguito ecco alcune implementazioni future che potrebbero essere sviluppate:\n",
    "        <ul>\n",
    "        <li>Espendere il supporto ad altri tipi di file.</li>\n",
    "        <li>Inviare un base64 all'IA così che possa essere in grado di ricostruire il file originale.</li>\n",
    "        <li>Ricavare automaticamente dati formali del mittente dal testo (se presenti, es: data documento, anagrafica mittente)</li>\n",
    "        </ul>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7b7f85",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h1>Conclusione</h1></center>\n",
    "<center><h2>Grazie per l'attenzione</h2></center>\n",
    "<div>\n",
    "    <p style='margin-top:2px'><h4 style='display:inline'>Studente</h4>:  Gioele Cavalli</p>\n",
    "    <p><h4 style='display:inline'>Progetto</h4>:  Documentinator</p>\n",
    "    <p><h4 style='display:inline'>Materia </h4> :  TAP</p>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
